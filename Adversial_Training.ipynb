{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1155fe888e44710beb0ab497cfa271c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfb86142292942098503db3540d454cb",
              "IPY_MODEL_d75da72c5c39442ab9188586e3820ee3",
              "IPY_MODEL_6a88ba75e2704f5c98d123ca832f3422"
            ],
            "layout": "IPY_MODEL_05a8d5d3b87c497fb502c0ae732e4b69"
          }
        },
        "cfb86142292942098503db3540d454cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfabd0c6ed164fb79d1a93f11646ac90",
            "placeholder": "​",
            "style": "IPY_MODEL_a868785cf9dd47ee9ee231bdcde314b2",
            "value": "config.json: 100%"
          }
        },
        "d75da72c5c39442ab9188586e3820ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b61f953f5ba849dfad7b9cd28a6bc4a9",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccec361482cd457d9a4561fffe5eb385",
            "value": 570
          }
        },
        "6a88ba75e2704f5c98d123ca832f3422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c21ff6138484efd8965718b1e34de30",
            "placeholder": "​",
            "style": "IPY_MODEL_c8203c6932544616992a563bf02cc65d",
            "value": " 570/570 [00:00&lt;00:00, 38.4kB/s]"
          }
        },
        "05a8d5d3b87c497fb502c0ae732e4b69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfabd0c6ed164fb79d1a93f11646ac90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a868785cf9dd47ee9ee231bdcde314b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b61f953f5ba849dfad7b9cd28a6bc4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccec361482cd457d9a4561fffe5eb385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c21ff6138484efd8965718b1e34de30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8203c6932544616992a563bf02cc65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a4801d3c1164a8da624d3c2d0982258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce536972976c4129a02864cf6167163a",
              "IPY_MODEL_6e86c21fe6ed42bf9372b3e5b3659043",
              "IPY_MODEL_015e8e0671e8489fa61ea2861504b2af"
            ],
            "layout": "IPY_MODEL_8a1cf6ddb10646a592d5566831f8a405"
          }
        },
        "ce536972976c4129a02864cf6167163a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47343d5c53254494a7b3f015073c5065",
            "placeholder": "​",
            "style": "IPY_MODEL_70d194bde7d7457ea61dc1878c9ec552",
            "value": "model.safetensors: 100%"
          }
        },
        "6e86c21fe6ed42bf9372b3e5b3659043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9bebdd0b6b94fad9b2ae73d46f9e98d",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_befe3b7dbaaf426fb94205e01e99d5da",
            "value": 440449768
          }
        },
        "015e8e0671e8489fa61ea2861504b2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8828a27294a540eca2de918ae2406195",
            "placeholder": "​",
            "style": "IPY_MODEL_8a03d84304b34a049a484e37d3e2cc1b",
            "value": " 440M/440M [00:02&lt;00:00, 198MB/s]"
          }
        },
        "8a1cf6ddb10646a592d5566831f8a405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47343d5c53254494a7b3f015073c5065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d194bde7d7457ea61dc1878c9ec552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9bebdd0b6b94fad9b2ae73d46f9e98d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "befe3b7dbaaf426fb94205e01e99d5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8828a27294a540eca2de918ae2406195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a03d84304b34a049a484e37d3e2cc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ace14f4dc6b4c319940b2c3f3e16c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c48d9d9eea04b4f8a09f153f131766e",
              "IPY_MODEL_cadd14e1801b459cabfb9d4aee6d18f7",
              "IPY_MODEL_f843b122a8074827a6267a426f126f9a"
            ],
            "layout": "IPY_MODEL_6ab0e014a89d4407b6f1a5783ce9169d"
          }
        },
        "9c48d9d9eea04b4f8a09f153f131766e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de2f5256b2f41c9b1a2f119add3f1e4",
            "placeholder": "​",
            "style": "IPY_MODEL_6f6b565f3edb43318b4f24dbee0fbbb8",
            "value": "Map: 100%"
          }
        },
        "cadd14e1801b459cabfb9d4aee6d18f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37220d1167db492fab269e416a532236",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f10adc11b41f4cfcaa9feddf75d7992d",
            "value": 872
          }
        },
        "f843b122a8074827a6267a426f126f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f61c562885c54f0592d500c10359877f",
            "placeholder": "​",
            "style": "IPY_MODEL_62dc1a4faba74cf0abab17568fadf978",
            "value": " 872/872 [00:00&lt;00:00, 1636.33 examples/s]"
          }
        },
        "6ab0e014a89d4407b6f1a5783ce9169d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de2f5256b2f41c9b1a2f119add3f1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6b565f3edb43318b4f24dbee0fbbb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37220d1167db492fab269e416a532236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10adc11b41f4cfcaa9feddf75d7992d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f61c562885c54f0592d500c10359877f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62dc1a4faba74cf0abab17568fadf978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zV67GK-Y0aB",
        "outputId": "c0c7a4f7-de2b-415b-ac91-dd5706c97544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 17 23:27:05 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0              27W /  70W |   2993MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets torch scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLMJ0cNQhCFt",
        "outputId": "6609ed1b-e9cf-4e7a-89b1-d4bb00a758dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load AG News - text classification 4 classes\n",
        "ag_news = load_dataset(\"ag_news\")\n",
        "\n",
        "# Load SST-2 - sentiment analysis - binary classification\n",
        "sst2 = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "print(ag_news[\"train\"][0])  # Print example from AG News\n",
        "print(sst2[\"train\"][0])     # Print example from SST-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY_0HJSNekIu",
        "outputId": "2b5a096f-f245-4570-8dfe-52dfbc9ee0c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
            "{'sentence': 'hide new secretions from the parental units ', 'label': 0, 'idx': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sst2[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sdjv_MYafdH",
        "outputId": "ca55a129-7f83-414a-b779-4108b494b8f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['sentence', 'label', 'idx'],\n",
            "    num_rows: 67349\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textattack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iRs14MeiFPV",
        "outputId": "c6750018-6f25-4c56-9fdb-852295a07008"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textattack\n",
            "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting bert-score>=0.3.5 (from textattack)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack) (0.8.1)\n",
            "Collecting flair (from textattack)\n",
            "  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack) (3.16.1)\n",
            "Collecting language-tool-python (from textattack)\n",
            "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting lemminflect (from textattack)\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting lru-dict (from textattack)\n",
            "  Downloading lru_dict-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: datasets>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (3.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack) (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.13.1)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (4.46.3)\n",
            "Collecting terminaltables (from textattack)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack) (4.66.6)\n",
            "Collecting word2number (from textattack)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from textattack)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack) (10.5.0)\n",
            "Collecting pinyin>=0.4.0 (from textattack)\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack) (0.42.1)\n",
            "Collecting OpenHowNet (from textattack)\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (24.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.4.0->textattack) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.26.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2024.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.4.5)\n",
            "Collecting boto3>=1.20.27 (from flair->textattack)\n",
            "  Downloading boto3-1.35.83-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair->textattack)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.15)\n",
            "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (5.2.0)\n",
            "Collecting langdetect>=1.0.9 (from flair->textattack)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (5.3.0)\n",
            "Collecting mpld3>=0.3 (from flair->textattack)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair->textattack)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.5.2)\n",
            "Collecting segtok>=1.5.11 (from flair->textattack)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.9.0)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
            "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting semver<4.0.0,>=3.0.0 (from flair->textattack)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language-tool-python->textattack) (24.1.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language-tool-python->textattack) (0.45.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (1.4.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree (from OpenHowNet->textattack)\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (75.1.0)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.36.0,>=1.35.83 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading botocore-1.35.83-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.18.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair->textattack) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (4.25.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (3.0.2)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (1.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.6)\n",
            "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (5.9.5)\n",
            "Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.7/445.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flair-0.14.0-py3-none-any.whl (776 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
            "Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lru_dict-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.35.83-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.83-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: pinyin, word2number, docopt, langdetect, pptree, sqlitedict, wikipedia-api, intervaltree\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630477 sha256=c53a095e0cdff91271283bc8d8f15fdcf172c732666c7a7430ed0dbe3664e0a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=f1abaf9bec1d9a5a49b546d67192a6a5ca9914b304f71398bdb47757ae18c723\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=97c52be1cbdce81cf054c76023c02f7568577b890bff06d082f790ba1324f98e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=df665051784c9a0925c5699e60b47665f9520d12bbb7b0a9ec0e1c1ff152a41b\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=4e43cf232af79abc52a4a60bfcd116155542f1adb2cfd515e1b08af3595027cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=20532ade7c41735e4a6955cb1dda511752cd08c81aee4d0aeed06e058bd41acf\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=be0d0417acc9e871787ce6d8efd824b7a73896a50fa0295c19544c000aaf0d0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=9e9868d32b0b483269d3f822bbd5ad9a20acfbb3f168d71772c8ae6f8aeb63ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built pinyin word2number docopt langdetect pptree sqlitedict wikipedia-api intervaltree\n",
            "Installing collected packages: word2number, sqlitedict, sortedcontainers, pptree, pinyin, docopt, terminaltables, semver, segtok, num2words, lru-dict, lemminflect, langdetect, jsonlines, jmespath, intervaltree, ftfy, conllu, anytree, wikipedia-api, OpenHowNet, language-tool-python, botocore, bioc, s3transfer, pytorch-revgrad, mpld3, boto3, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
            "Successfully installed OpenHowNet-2.0 anytree-2.12.1 bert-score-0.3.13 bioc-2.1 boto3-1.35.83 botocore-1.35.83 conllu-4.5.3 docopt-0.6.2 flair-0.14.0 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 language-tool-python-2.8.1 lemminflect-0.2.3 lru-dict-1.3.0 mpld3-0.5.10 num2words-0.5.14 pinyin-0.4.0 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.10.4 segtok-1.5.11 semver-3.0.2 sortedcontainers-2.4.0 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.10 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.7.1 word2number-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textattack\n",
        "from textattack.attack_recipes import TextFoolerJin2019\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
        "\n",
        "# Define Attack\n",
        "attack = TextFoolerJin2019.build(model_wrapper)\n",
        "\n",
        "# Example input\n",
        "input_text = \"The economy is looking good for the next quarter.\"\n",
        "label = 2  # Label for \"Business\"\n",
        "\n",
        "# Generate adversarial example\n",
        "attack_result = attack.attack(textattack.shared.AttackedText(input_text), label)\n",
        "print(\"Original Text:\", input_text)\n",
        "print(\"Adversarial Example:\", attack_result.perturbed_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648,
          "referenced_widgets": [
            "f1155fe888e44710beb0ab497cfa271c",
            "cfb86142292942098503db3540d454cb",
            "d75da72c5c39442ab9188586e3820ee3",
            "6a88ba75e2704f5c98d123ca832f3422",
            "05a8d5d3b87c497fb502c0ae732e4b69",
            "dfabd0c6ed164fb79d1a93f11646ac90",
            "a868785cf9dd47ee9ee231bdcde314b2",
            "b61f953f5ba849dfad7b9cd28a6bc4a9",
            "ccec361482cd457d9a4561fffe5eb385",
            "3c21ff6138484efd8965718b1e34de30",
            "c8203c6932544616992a563bf02cc65d",
            "5a4801d3c1164a8da624d3c2d0982258",
            "ce536972976c4129a02864cf6167163a",
            "6e86c21fe6ed42bf9372b3e5b3659043",
            "015e8e0671e8489fa61ea2861504b2af",
            "8a1cf6ddb10646a592d5566831f8a405",
            "47343d5c53254494a7b3f015073c5065",
            "70d194bde7d7457ea61dc1878c9ec552",
            "a9bebdd0b6b94fad9b2ae73d46f9e98d",
            "befe3b7dbaaf426fb94205e01e99d5da",
            "8828a27294a540eca2de918ae2406195",
            "8a03d84304b34a049a484e37d3e2cc1b"
          ]
        },
        "id": "O1_U00y9ihhx",
        "outputId": "5ae6cfbb-e605-46a7-a495-5bfae7fd8201"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Updating TextAttack package dependencies.\n",
            "textattack: Downloading NLTK required packages.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1155fe888e44710beb0ab497cfa271c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a4801d3c1164a8da624d3c2d0982258"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AutoTokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-abdcb1e2b6da>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Step 1: Load Pretrained Model and Tokenizer\n",
        "MODEL_NAME = \"bert-base-uncased\"  # Choose any Hugging Face model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "\n",
        "# Device setup (CUDA if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Step 2: Load and Preprocess Dataset\n",
        "def preprocess_data(examples):\n",
        "    return tokenizer(examples['sentence'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "# Load a sample dataset (SST-2 binary classification)\n",
        "dataset = load_dataset(\"sst2\")\n",
        "train_dataset = dataset['train'].map(preprocess_data, batched=True)\n",
        "test_dataset = dataset['validation'].map(preprocess_data, batched=True)\n",
        "\n",
        "# Convert to PyTorch-compatible format\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Step 3: Fine-tune the Model on Clean Data\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"Training on clean data...\")\n",
        "model.train()\n",
        "for epoch in range(2):  # Train for 2 epochs\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = torch.tensor(batch['input_ids']).to(device)\n",
        "        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
        "        labels = torch.tensor(batch['label']).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} completed.\")\n",
        "\n",
        "model.save_pretrained(\"saved_model\")\n",
        "tokenizer.save_pretrained(\"saved_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "3ace14f4dc6b4c319940b2c3f3e16c63",
            "9c48d9d9eea04b4f8a09f153f131766e",
            "cadd14e1801b459cabfb9d4aee6d18f7",
            "f843b122a8074827a6267a426f126f9a",
            "6ab0e014a89d4407b6f1a5783ce9169d",
            "6de2f5256b2f41c9b1a2f119add3f1e4",
            "6f6b565f3edb43318b4f24dbee0fbbb8",
            "37220d1167db492fab269e416a532236",
            "f10adc11b41f4cfcaa9feddf75d7992d",
            "f61c562885c54f0592d500c10359877f",
            "62dc1a4faba74cf0abab17568fadf978"
          ]
        },
        "id": "tBUdNTNyivXo",
        "outputId": "371ffcb6-875f-4bdb-cae3-26fcc621700c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ace14f4dc6b4c319940b2c3f3e16c63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [11:59<?, ?it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "<ipython-input-13-ce5b9b951285>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = torch.tensor(batch['input_ids']).to(device)\n",
            "<ipython-input-13-ce5b9b951285>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
            "<ipython-input-13-ce5b9b951285>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(batch['label']).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on clean data...\n",
            "Epoch 1 completed.\n",
            "Epoch 2 completed.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('saved_model/tokenizer_config.json',\n",
              " 'saved_model/special_tokens_map.json',\n",
              " 'saved_model/vocab.txt',\n",
              " 'saved_model/added_tokens.json',\n",
              " 'saved_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Generate Adversarial Examples using TextAttack\n",
        "print(\"Generating adversarial examples...\")\n",
        "\n",
        "from textattack.attack_recipes import TextFoolerJin2019\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "#from textattack.attacks import Attack\n",
        "from textattack import Attacker, AttackArgs\n",
        "from textattack.datasets import Dataset as TextAttackDataset\n",
        "#from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Load the model\n",
        "#model = AutoModelForSequenceClassification.from_pretrained(\"saved_model\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"saved_model\")\n",
        "\n",
        "# Wrap the model for TextAttack\n",
        "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
        "\n",
        "# Define the adversarial attack (TextFooler)\n",
        "attack = TextFoolerJin2019.build(model_wrapper)\n",
        "print(test_dataset[0])\n",
        "# Convert HuggingFace dataset to TextAttack format\n",
        "test_samples = []\n",
        "for ex in test_dataset:\n",
        "    text = tokenizer.decode(ex['input_ids'], skip_special_tokens=True)  # Decode input_ids to text\n",
        "    label = ex['label'].item()\n",
        "    #test_samples.append({'text': text, 'label': label})\n",
        "\n",
        "    test_samples.append((text, label))\n",
        "\n",
        "# Now, create a TextAttack dataset\n",
        "textattack_dataset = TextAttackDataset(test_samples)\n",
        "print(test_samples[0])\n",
        "# Verify the dataset\n",
        "#print(f\"first element: {textattack_dataset[0][0]['text']}\")  # Check the first element\n",
        "# Set attack arguments\n",
        "attack_args = AttackArgs(\n",
        "    num_examples=50,  # Generate adversarial examples for 50 samples\n",
        "    log_to_csv=\"adversarial_examples.csv\",  # Save the adversarial examples\n",
        "    disable_stdout=False,\n",
        ")\n",
        "# Run the attack\n",
        "attacker = Attacker(attack, textattack_dataset, attack_args)\n",
        "attack_results = attacker.attack_dataset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSFoL8HS40Gl",
        "outputId": "f34e6131-353e-4143-bec8-6ca0363b2755"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating adversarial examples...\n",
            "{'label': tensor(1), 'input_ids': tensor([  101,  2009,  1005,  1055,  1037, 11951,  1998,  2411, 12473,  4990,\n",
            "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Logging to CSV at path adversarial_examples.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"it ' s a charming and often affecting journey.\", 1)\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   2%|▏         | 1/50 [00:15<12:34, 15.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 1 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (99%)]]\n",
            "\n",
            "it ' s a [[charming]] and [[often]] [[affecting]] [[journey]].\n",
            "\n",
            "it ' s a [[cutie]] and [[repeatedly]] [[repercussions]] [[itineraries]].\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:   4%|▍         | 2/50 [00:16<06:32,  8.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 2 ---------------------------------------------\n",
            "[[0 (92%)]] --> [[1 (72%)]]\n",
            "\n",
            "unflinchingly [[bleak]] and desperate\n",
            "\n",
            "unflinchingly [[eerie]] and desperate\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:   6%|▌         | 3/50 [00:18<04:51,  6.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 3 ---------------------------------------------\n",
            "[[1 (97%)]] --> [[0 (69%)]]\n",
            "\n",
            "[[allows]] us to hope that nolan is poised to embark a major [[career]] as a commercial yet inventive filmmaker.\n",
            "\n",
            "[[authorised]] us to hope that nolan is poised to embark a major [[occupational]] as a commercial yet inventive filmmaker.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:   8%|▊         | 4/50 [00:20<03:50,  5.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 4 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (58%)]]\n",
            "\n",
            "the acting, costumes, music, cinematography and sound are all [[astounding]] given the [[production]] ' s austere locales.\n",
            "\n",
            "the acting, costumes, music, cinematography and sound are all [[extraordinaire]] given the [[manufacture]] ' s austere locales.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  10%|█         | 5/50 [00:22<03:20,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 5 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (98%)]]\n",
            "\n",
            "it ' s [[slow]] - - [[very]], very [[slow]].\n",
            "\n",
            "it ' s [[lento]] - - [[perfectly]], very [[lent]].\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 6 / 0 / 0 / 6:  12%|█▏        | 6/50 [00:24<03:00,  4.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 6 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (52%)]]\n",
            "\n",
            "although laced with humor and a few fanciful touches, the [[film]] is a [[refreshingly]] serious look at young women.\n",
            "\n",
            "although laced with humor and a few fanciful touches, the [[moviemaking]] is a [[nonchalantly]] serious look at young women.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 0 / 7:  14%|█▍        | 7/50 [00:25<02:39,  3.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 7 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (63%)]]\n",
            "\n",
            "a sometimes [[tedious]] film.\n",
            "\n",
            "a sometimes [[uphill]] film.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 8 / 0 / 0 / 8:  16%|█▌        | 8/50 [00:27<02:23,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 8 ---------------------------------------------\n",
            "[[0 (94%)]] --> [[1 (55%)]]\n",
            "\n",
            "or doing last year ' s [[taxes]] with your ex - wife.\n",
            "\n",
            "or doing last year ' s [[honorarium]] with your ex - wife.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 0 / 9:  18%|█▊        | 9/50 [00:30<02:17,  3.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 9 ---------------------------------------------\n",
            "[[1 (75%)]] --> [[0 (58%)]]\n",
            "\n",
            "you do n ' t have to know about music to [[appreciate]] the film ' s easygoing blend of [[comedy]] and romance.\n",
            "\n",
            "you do n ' t have to know about music to [[appreciating]] the film ' s easygoing blend of [[derision]] and romance.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 0 / 10:  20%|██        | 10/50 [00:34<02:17,  3.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 10 ---------------------------------------------\n",
            "[[0 (98%)]] --> [[1 (66%)]]\n",
            "\n",
            "in [[exactly]] 89 [[minutes]], most of which passed as [[slowly]] as if i ' d been sitting naked on an igloo, formula 51 [[sank]] from quirky to jerky to [[utter]] turkey.\n",
            "\n",
            "in [[faithfully]] 89 [[minute]], most of which passed as [[sweetly]] as if i ' d been sitting naked on an igloo, formula 51 [[plunged]] from quirky to jerky to [[totality]] turkey.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 0 / 11:  22%|██▏       | 11/50 [00:37<02:13,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 11 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (58%)]]\n",
            "\n",
            "the mesmerizing performances of the leads [[keep]] the film grounded and [[keep]] the audience riveted.\n",
            "\n",
            "the mesmerizing performances of the leads [[conserve]] the film grounded and [[conserve]] the audience riveted.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 12 / 0 / 0 / 12:  24%|██▍       | 12/50 [00:42<02:13,  3.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 12 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (70%)]]\n",
            "\n",
            "it takes a strange kind of [[laziness]] to [[waste]] the talents of robert forster, anne meara, [[eugene]] levy, and reginald veljohnson all in the same [[movie]].\n",
            "\n",
            "it takes a strange kind of [[nonchalance]] to [[litter]] the talents of robert forster, anne meara, [[melendez]] levy, and reginald veljohnson all in the same [[photograph]].\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 13 / 0 / 1 / 14:  28%|██▊       | 14/50 [00:44<01:55,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 13 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (60%)]]\n",
            "\n",
            "... the film [[suffers]] from a [[lack]] of humor ( something needed to balance out the violence )...\n",
            "\n",
            "... the film [[heartbreak]] from a [[lacking]] of humor ( something needed to balance out the violence )...\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 14 ---------------------------------------------\n",
            "[[0 (64%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "we root for ( clara and paul ), even like them, though perhaps it ' s an emotion closer to pity.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 14 / 0 / 1 / 15:  30%|███       | 15/50 [00:47<01:50,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 15 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (83%)]]\n",
            "\n",
            "even horror fans will most likely not find what they ' re [[seeking]] with trouble every day ; the movie [[lacks]] both thrills and humor.\n",
            "\n",
            "even horror fans will most likely not find what they ' re [[find]] with trouble every day ; the movie [[dearth]] both thrills and humor.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Succeeded / Failed / Skipped / Total] 14 / 1 / 1 / 16:  32%|███▏      | 16/50 [00:57<02:02,  3.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 16 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "a gorgeous, high - spirited musical from india that exquisitely blends music, dance, song, and high drama.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 15 / 1 / 1 / 17:  34%|███▍      | 17/50 [00:58<01:53,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 17 ---------------------------------------------\n",
            "[[1 (97%)]] --> [[0 (64%)]]\n",
            "\n",
            "the [[emotions]] are [[raw]] and will strike a nerve with anyone who ' s ever had family trauma.\n",
            "\n",
            "the [[sentiments]] are [[crus]] and will strike a nerve with anyone who ' s ever had family trauma.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 16 / 1 / 1 / 18:  36%|███▌      | 18/50 [01:01<01:49,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 18 ---------------------------------------------\n",
            "[[1 (97%)]] --> [[0 (53%)]]\n",
            "\n",
            "audrey tatou has a [[knack]] for picking roles that magnify her outrageous [[charm]], and in this [[literate]] [[french]] [[comedy]], she ' s as morning - glory exuberant as she was in amelie.\n",
            "\n",
            "audrey tatou has a [[fancy]] for picking roles that magnify her outrageous [[exudes]], and in this [[schooled]] [[english]] [[ridicule]], she ' s as morning - glory exuberant as she was in amelie.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 16 / 2 / 1 / 19:  38%|███▊      | 19/50 [01:05<01:46,  3.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 19 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[[FAILED]]]\n",
            "\n",
            "... the movie is just a plain old monster.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 17 / 2 / 1 / 20:  40%|████      | 20/50 [01:07<01:40,  3.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 20 ---------------------------------------------\n",
            "[[0 (98%)]] --> [[1 (64%)]]\n",
            "\n",
            "in its best moments, resembles a [[bad]] high school production of grease, without benefit of song.\n",
            "\n",
            "in its best moments, resembles a [[unfavourable]] high school production of grease, without benefit of song.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 18 / 2 / 1 / 21:  42%|████▏     | 21/50 [01:08<01:34,  3.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 21 ---------------------------------------------\n",
            "[[0 (82%)]] --> [[1 (71%)]]\n",
            "\n",
            "pumpkin takes an admirable look at the hypocrisy of political correctness, but it does so with such an [[uneven]] tone that you never know when humor ends and tragedy begins.\n",
            "\n",
            "pumpkin takes an admirable look at the hypocrisy of political correctness, but it does so with such an [[lopsided]] tone that you never know when humor ends and tragedy begins.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 19 / 2 / 2 / 23:  46%|████▌     | 23/50 [01:09<01:21,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 22 ---------------------------------------------\n",
            "[[0 (96%)]] --> [[1 (61%)]]\n",
            "\n",
            "the iditarod [[lasts]] for [[days]] - this just felt like it did.\n",
            "\n",
            "the iditarod [[matures]] for [[time]] - this just felt like it did.\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 23 ---------------------------------------------\n",
            "[[1 (84%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "holden caulfield did it better.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 20 / 2 / 2 / 24:  48%|████▊     | 24/50 [01:14<01:20,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 24 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (96%)]]\n",
            "\n",
            "a [[delectable]] and [[intriguing]] [[thriller]] filled with [[surprises]], [[read]] my [[lips]] is an [[original]].\n",
            "\n",
            "a [[glamorous]] and [[staggering]] [[slasher]] filled with [[stupor]], [[lee]] my [[mouths]] is an [[primordial]].\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Succeeded / Failed / Skipped / Total] 21 / 2 / 2 / 25:  50%|█████     | 25/50 [01:15<01:15,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 25 ---------------------------------------------\n",
            "[[1 (80%)]] --> [[0 (84%)]]\n",
            "\n",
            "seldom has a movie [[so]] closely matched the spirit of a man and his work.\n",
            "\n",
            "seldom has a movie [[too]] closely matched the spirit of a man and his work.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 22 / 2 / 2 / 26:  52%|█████▏    | 26/50 [01:17<01:11,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 26 ---------------------------------------------\n",
            "[[0 (94%)]] --> [[1 (51%)]]\n",
            "\n",
            "nicks, seemingly uncertain what ' s going to make people laugh, runs the [[gamut]] from stale parody to raunchy sex [[gags]] to formula romantic comedy.\n",
            "\n",
            "nicks, seemingly uncertain what ' s going to make people laugh, runs the [[ranging]] from stale parody to raunchy sex [[jaws]] to formula romantic comedy.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Succeeded / Failed / Skipped / Total] 22 / 3 / 2 / 27:  54%|█████▍    | 27/50 [01:26<01:13,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 27 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[[FAILED]]]\n",
            "\n",
            "the action switches between past and present, but the material link is too tenuous to anchor the emotional connections that purport to span a 125 - year divide.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 23 / 3 / 2 / 28:  56%|█████▌    | 28/50 [01:28<01:09,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 28 ---------------------------------------------\n",
            "[[1 (99%)]] --> [[0 (68%)]]\n",
            "\n",
            "it ' s an offbeat [[treat]] that pokes fun at the democratic exercise while also examining its significance for those who take part.\n",
            "\n",
            "it ' s an offbeat [[processed]] that pokes fun at the democratic exercise while also examining its significance for those who take part.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 24 / 3 / 2 / 29:  58%|█████▊    | 29/50 [01:30<01:05,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 29 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (53%)]]\n",
            "\n",
            "it ' s a cookie - [[cutter]] [[movie]], a cut - and - [[paste]] job.\n",
            "\n",
            "it ' s a cookie - [[assembler]] [[productions]], a cut - and - [[sticking]] job.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 25 / 3 / 2 / 30:  60%|██████    | 30/50 [01:31<01:00,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 30 ---------------------------------------------\n",
            "[[0 (81%)]] --> [[1 (77%)]]\n",
            "\n",
            "i had to look away - this was god [[awful]].\n",
            "\n",
            "i had to look away - this was god [[heinous]].\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 26 / 3 / 2 / 31:  62%|██████▏   | 31/50 [01:33<00:57,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 31 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (51%)]]\n",
            "\n",
            "[[thanks]] to scott ' s charismatic roger and eisenberg ' s sweet nephew, roger dodger is one of the most [[compelling]] variations on in the company of men.\n",
            "\n",
            "[[merci]] to scott ' s charismatic roger and eisenberg ' s sweet nephew, roger dodger is one of the most [[unconvincing]] variations on in the company of men.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 27 / 3 / 2 / 32:  64%|██████▍   | 32/50 [01:35<00:53,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 32 ---------------------------------------------\n",
            "[[0 (90%)]] --> [[1 (75%)]]\n",
            "\n",
            "... designed to provide a mix of smiles and tears, ` ` crossroads ' ' [[instead]] provokes a handful of unintentional howlers and numerous yawns.\n",
            "\n",
            "... designed to provide a mix of smiles and tears, ` ` crossroads ' ' [[rather]] provokes a handful of unintentional howlers and numerous yawns.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 27 / 4 / 2 / 33:  66%|██████▌   | 33/50 [01:39<00:51,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 33 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "a gorgeous, witty, seductive movie.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 27 / 5 / 2 / 34:  68%|██████▊   | 34/50 [01:46<00:50,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 34 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[[FAILED]]]\n",
            "\n",
            "if the movie succeeds in instilling a wary sense of ` there but for the grace of god, ' it is far too self - conscious to draw you deeply into its world.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 27 / 6 / 2 / 35:  70%|███████   | 35/50 [01:50<00:47,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 35 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[[FAILED]]]\n",
            "\n",
            "it does n ' t believe in itself, it has no sense of humor... it ' s just plain bored.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 28 / 6 / 2 / 36:  72%|███████▏  | 36/50 [01:51<00:43,  3.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 36 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (86%)]]\n",
            "\n",
            "a sequence of [[ridiculous]] shoot - ' em - up scenes.\n",
            "\n",
            "a sequence of [[nutty]] shoot - ' em - up scenes.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 29 / 6 / 2 / 37:  74%|███████▍  | 37/50 [01:52<00:39,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 37 ---------------------------------------------\n",
            "[[1 (89%)]] --> [[0 (89%)]]\n",
            "\n",
            "the weight of the piece, the unerring professionalism of the chilly production, and the [[fascination]] embedded in the lurid topic prove recommendation enough.\n",
            "\n",
            "the weight of the piece, the unerring professionalism of the chilly production, and the [[allure]] embedded in the lurid topic prove recommendation enough.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 30 / 6 / 2 / 38:  76%|███████▌  | 38/50 [01:53<00:35,  2.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 38 ---------------------------------------------\n",
            "[[0 (98%)]] --> [[1 (61%)]]\n",
            "\n",
            "( w ) hile long on amiable monkeys and worthy environmentalism, jane goodall ' s wild chimpanzees is [[short]] on the thrills the oversize medium demands.\n",
            "\n",
            "( w ) hile long on amiable monkeys and worthy environmentalism, jane goodall ' s wild chimpanzees is [[abstract]] on the thrills the oversize medium demands.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 31 / 6 / 2 / 39:  78%|███████▊  | 39/50 [01:55<00:32,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 39 ---------------------------------------------\n",
            "[[1 (92%)]] --> [[0 (53%)]]\n",
            "\n",
            "as surreal as a dream and as [[detailed]] as a [[photograph]], as visually dexterous as it is at times imaginatively overwhelming.\n",
            "\n",
            "as surreal as a dream and as [[circumspect]] as a [[photographed]], as visually dexterous as it is at times imaginatively overwhelming.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 32 / 6 / 2 / 40:  80%|████████  | 40/50 [01:55<00:28,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 40 ---------------------------------------------\n",
            "[[1 (97%)]] --> [[0 (76%)]]\n",
            "\n",
            "escaping the studio, piccoli is [[warmly]] affecting and so is this adroitly minimalist movie.\n",
            "\n",
            "escaping the studio, piccoli is [[ardent]] affecting and so is this adroitly minimalist movie.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 33 / 6 / 2 / 41:  82%|████████▏ | 41/50 [01:58<00:26,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 41 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (83%)]]\n",
            "\n",
            "there ' s... [[tremendous]] [[energy]] from the [[cast]], a sense of playfulness and excitement that seems [[appropriate]].\n",
            "\n",
            "there ' s... [[redoubtable]] [[vigour]] from the [[molding]], a sense of playfulness and excitement that seems [[punctual]].\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 34 / 6 / 2 / 42:  84%|████████▍ | 42/50 [02:04<00:23,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 42 ---------------------------------------------\n",
            "[[1 (99%)]] --> [[0 (67%)]]\n",
            "\n",
            "this [[illuminating]] documentary [[transcends]] our preconceived [[vision]] of the holy land and its inhabitants, revealing the human [[complexities]] beneath.\n",
            "\n",
            "this [[instructional]] documentary [[outshines]] our preconceived [[premonition]] of the holy land and its inhabitants, revealing the human [[complicating]] beneath.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 35 / 6 / 2 / 43:  86%|████████▌ | 43/50 [02:05<00:20,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 43 ---------------------------------------------\n",
            "[[1 (97%)]] --> [[0 (71%)]]\n",
            "\n",
            "the subtle [[strength]] of ` ` elling ' ' is that it never [[loses]] touch with the reality of the grim situation.\n",
            "\n",
            "the subtle [[force]] of ` ` elling ' ' is that it never [[loosing]] touch with the reality of the grim situation.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 36 / 6 / 2 / 44:  88%|████████▊ | 44/50 [02:07<00:17,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 44 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (57%)]]\n",
            "\n",
            "holm... [[embodies]] the character with an [[effortlessly]] regal charisma.\n",
            "\n",
            "holm... [[archetype]] the character with an [[conveniently]] regal charisma.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 37 / 6 / 2 / 45:  90%|█████████ | 45/50 [02:07<00:14,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 45 ---------------------------------------------\n",
            "[[0 (55%)]] --> [[1 (50%)]]\n",
            "\n",
            "the title not only describes its main characters, but the [[lazy]] people behind the camera as well.\n",
            "\n",
            "the title not only describes its main characters, but the [[unmotivated]] people behind the camera as well.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 38 / 6 / 2 / 46:  92%|█████████▏| 46/50 [02:09<00:11,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 46 ---------------------------------------------\n",
            "[[0 (98%)]] --> [[1 (94%)]]\n",
            "\n",
            "it offers [[little]] beyond the momentary joys of pretty and weightless intellectual entertainment.\n",
            "\n",
            "it offers [[humble]] beyond the momentary joys of pretty and weightless intellectual entertainment.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 39 / 6 / 2 / 47:  94%|█████████▍| 47/50 [02:10<00:08,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 47 ---------------------------------------------\n",
            "[[0 (82%)]] --> [[1 (60%)]]\n",
            "\n",
            "a synthesis of [[cliches]] and absurdities that seems positively decadent in its cinematic flash and emptiness.\n",
            "\n",
            "a synthesis of [[dominguez]] and absurdities that seems positively decadent in its cinematic flash and emptiness.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 40 / 6 / 2 / 48:  96%|█████████▌| 48/50 [02:12<00:05,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 48 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (99%)]]\n",
            "\n",
            "a subtle and [[well]] - [[crafted]] ( for the most part ) chiller.\n",
            "\n",
            "a subtle and [[too]] - [[fabricated]] ( for the most part ) chiller.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 41 / 6 / 2 / 49:  98%|█████████▊| 49/50 [02:12<00:02,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 49 ---------------------------------------------\n",
            "[[1 (99%)]] --> [[0 (92%)]]\n",
            "\n",
            "has a [[lot]] of the virtues of eastwood at his best.\n",
            "\n",
            "has a [[shipments]] of the virtues of eastwood at his best.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 42 / 6 / 2 / 50: 100%|██████████| 50/50 [02:14<00:00,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 50 ---------------------------------------------\n",
            "[[0 (99%)]] --> [[1 (56%)]]\n",
            "\n",
            "it ' s [[hampered]] by a lifetime - channel kind of plot and a lead actress who is out of her depth.\n",
            "\n",
            "it ' s [[bothered]] by a lifetime - channel kind of plot and a lead actress who is out of her depth.\n",
            "\n",
            "\n",
            "\n",
            "+-------------------------------+-------+\n",
            "| Attack Results                |       |\n",
            "+-------------------------------+-------+\n",
            "| Number of successful attacks: | 42    |\n",
            "| Number of failed attacks:     | 6     |\n",
            "| Number of skipped attacks:    | 2     |\n",
            "| Original accuracy:            | 96.0% |\n",
            "| Accuracy under attack:        | 12.0% |\n",
            "| Attack success rate:          | 87.5% |\n",
            "| Average perturbed word %:     | 14.7% |\n",
            "| Average num. words per input: | 16.6  |\n",
            "| Avg num queries:              | 86.67 |\n",
            "+-------------------------------+-------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "\n",
        "# Load the adversarial examples\n",
        "adv_examples = pd.read_csv(\"adversarial_examples.csv\")\n",
        "\n",
        "# Extract original and adversarial texts\n",
        "original_texts = adv_examples['original_text'].tolist()\n",
        "adversarial_texts = adv_examples['perturbed_text'].tolist()\n",
        "labels = adv_examples['ground_truth_output'].tolist()\n",
        "\n",
        "# Function to evaluate a list of inputs\n",
        "def evaluate_model_on_texts(texts, labels, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predicted = torch.argmax(outputs.logits, dim=1).item()\n",
        "            predictions.append(predicted)\n",
        "    return accuracy_score(labels, predictions), predictions\n",
        "\n",
        "# Baseline Evaluation on Adversarial Examples (Before Robust Training)\n",
        "print(\"Evaluating on adversarial examples BEFORE robust training...\")\n",
        "adv_accuracy_before, _ = evaluate_model_on_texts(adversarial_texts, labels, model, tokenizer, device)\n",
        "print(f\"Accuracy on adversarial examples (Before): {adv_accuracy_before * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSawdJTXc6iJ",
        "outputId": "de37b1f0-c8d9-4385-f8c2-97f68c8d7ce1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on adversarial examples BEFORE robust training...\n",
            "Accuracy on adversarial examples (Before): 58.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Combine Clean and Adversarial Data for Robust Training\n",
        "print(\"Preparing data for robust training...\")\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Load adversarial examples from CSV\n",
        "adv_examples = pd.read_csv(\"adversarial_examples.csv\")\n",
        "\n",
        "# Create a combined dataset: clean + adversarial\n",
        "combined_data = []\n",
        "for idx, row in adv_examples.iterrows():\n",
        "    combined_data.append({\"text\": row[\"original_text\"], \"label\": row[\"ground_truth_output\"]})\n",
        "    combined_data.append({\"text\": row[\"perturbed_text\"], \"label\": row[\"ground_truth_output\"]})\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[idx][\"text\"]\n",
        "        label = self.data[idx][\"label\"]\n",
        "\n",
        "        # Tokenize the text\n",
        "        tokenized = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # Squeeze batch dimension and return as dictionary\n",
        "        return {\n",
        "            \"input_ids\": tokenized[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": tokenized[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Step 2: Create PyTorch dataset and dataloader\n",
        "combined_dataset = CustomDataset(combined_data, tokenizer)\n",
        "robust_train_dataloader = DataLoader(combined_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Step 6: Retrain the Model on Combined Data (Clean + Adversarial)\n",
        "print(\"Training on clean and adversarial data...\")\n",
        "model.train()\n",
        "for epoch in range(2):  # Robust training for 2 epochs\n",
        "    for batch in robust_train_dataloader:\n",
        "        input_ids = torch.tensor(batch['input_ids']).to(device)\n",
        "        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
        "        labels = torch.tensor(batch['label']).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} of robust training completed.\")\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "print(\"Evaluating the model...\")\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = torch.tensor(batch['input_ids']).to(device)\n",
        "        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
        "        labels = torch.tensor(batch['label']).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdWH3BS-sumu",
        "outputId": "b6df91ca-4f79-4298-dac6-217d039ac4a1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data for robust training...\n",
            "Training on clean and adversarial data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-205457b6a5f0>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = torch.tensor(batch['input_ids']).to(device)\n",
            "<ipython-input-46-205457b6a5f0>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
            "<ipython-input-46-205457b6a5f0>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(batch['label']).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of robust training completed.\n",
            "Epoch 2 of robust training completed.\n",
            "Evaluating the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-205457b6a5f0>:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = torch.tensor(batch['input_ids']).to(device)\n",
            "<ipython-input-46-205457b6a5f0>:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
            "<ipython-input-46-205457b6a5f0>:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(batch['label']).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 89.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Define the output directory\n",
        "output_dir = \"./trained_model\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save the trained model and tokenizer\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTJU8HJWmQOL",
        "outputId": "718b96ef-dca5-492c-f804-08c09bfc6c2a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to ./trained_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Clean Test Data\n",
        "print(\"Evaluating on clean test data...\")\n",
        "test_texts = [ex['sentence'] for ex in test_dataset]\n",
        "test_labels = [ex['label'] for ex in test_dataset]\n",
        "clean_accuracy, _ = evaluate_model_on_texts(test_texts, test_labels, model, tokenizer, device)\n",
        "print(f\"Accuracy on clean test data: {clean_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "P6vP-TNdeXiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on Adversarial Examples (After Robust Training)\n",
        "print(\"Evaluating on adversarial examples AFTER robust training...\")\n",
        "adv_accuracy_after, _ = evaluate_model_on_texts(adversarial_texts, labels, model, tokenizer, device)\n",
        "print(f\"Accuracy on adversarial examples (After): {adv_accuracy_after * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "9PeMU-_heY6b",
        "outputId": "23f48a97-f043-4635-9b0a-5eff17bd8411"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on adversarial examples AFTER robust training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [8, 50]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-1b93295a8c8b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluation on Adversarial Examples (After Robust Training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on adversarial examples AFTER robust training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0madv_accuracy_after\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversarial_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy on adversarial examples (After): {adv_accuracy_after * 100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-b0de99e285ab>\u001b[0m in \u001b[0;36mevaluate_model_on_texts\u001b[0;34m(texts, labels, model, tokenizer, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Baseline Evaluation on Adversarial Examples (Before Robust Training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"\n\u001b[1;32m    102\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8, 50]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load adversarial examples from CSV\n",
        "adv_examples = pd.read_csv(\"adversarial_examples.csv\")\n",
        "\n",
        "# Prepare adversarial texts and labels\n",
        "adv_texts = adv_examples[\"perturbed_text\"].tolist()\n",
        "adv_labels = adv_examples[\"ground_truth_output\"].tolist()\n",
        "\n",
        "# Evaluate the model on adversarial examples\n",
        "adv_accuracy, adv_predictions = evaluate_model_on_texts(adv_texts, adv_labels, model, tokenizer, device)\n",
        "\n",
        "print(f\"Accuracy on adversarial examples after training: {adv_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUntmBGpmbw8",
        "outputId": "b7d67f54-a28f-41bb-8787-ca86506ad818"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on adversarial examples after training: 98.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NzApC5rnlZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}